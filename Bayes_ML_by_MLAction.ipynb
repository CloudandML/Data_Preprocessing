{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习实战 Machine Learning in Action\n",
    "#### 4. navie bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class bayes:\n",
    "    \n",
    "    def createVocabList(self,dataset):\n",
    "        vocabSet = set([])\n",
    "        for document in dataset:\n",
    "            vocabSet = vocabSet | set(document)\n",
    "        return list(vocabSet)\n",
    "    \n",
    "    def setofWord2Vec(self,vocabList,inputSet):\n",
    "        returnVec = [0]*len(vocabList) #a list \n",
    "        for word in inputSet:\n",
    "            if word in vocabList:\n",
    "                returnVec[vocabList.index(word)] = 1\n",
    "            else :\n",
    "                print('the word: %s is not in my Vocabulary! ' %word)\n",
    "        return returnVec\n",
    "    \n",
    "    #navie bayes classifier training\n",
    "    def trainNB0(self,dataset, labels):\n",
    "        self.labels = labels\n",
    "        self.vocabSetlist = self.createVocabList(dataset)\n",
    "        train_Matrix = []\n",
    "        for w in dataset: \n",
    "            train_Matrix.append(self.setofWord2Vec(self.vocabSetlist,w))\n",
    "        numTrainDocs = len(train_Matrix)\n",
    "        numWords = len(train_Matrix[0])\n",
    "        self.pAbusive = sum(labels)/float(numTrainDocs) #样本为1的比例\n",
    "        p_0_Num = np.zeros(numWords)\n",
    "        p_1_Num = np.zeros(numWords)\n",
    "        p_0_Denom = 0.0\n",
    "        p_1_Denom = 0.0\n",
    "        for i in range(numTrainDocs):\n",
    "            if labels[i] ==1:\n",
    "                p_1_Num += train_Matrix[i]\n",
    "                p_1_Denom += sum(train_Matrix[i])\n",
    "            else:\n",
    "                p_0_Num += train_Matrix[i]\n",
    "                p_0_Denom += sum(train_Matrix[i])\n",
    "        self.p_1_Vec = np.log(p_1_Num/p_1_Denom + 1e-5)\n",
    "        self.p_0_Vec = np.log(p_0_Num/p_0_Denom+ 1e-5) \n",
    "        return self.p_0_Vec, self.p_1_Vec, self.pAbusive\n",
    "    \n",
    "    \n",
    "    #\n",
    "    def classifyNB(self,vec2Classify, p_0_Vec, \n",
    "                   p_1_Vec, pClass1):\n",
    "        # 元素相乘\n",
    "        p_1 = sum(vec2Classify * p_1_Vec)  + np.log(pClass1)\n",
    "        p_0 = sum(vec2Classify * p_0_Vec) + np.log(1.0 - pClass1)\n",
    "        if p_1 > p_0:\n",
    "            return 1\n",
    "        else :\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def testingNB(self,test_data):\n",
    "        #myVocabList = createVocabList(test_data)\n",
    "        test_Matrix =[]\n",
    "        preds = []\n",
    "        for testd in test_data:\n",
    "            test_Matrix = self.setofWord2Vec(self.vocabSetlist,testd)\n",
    "            pred = self.classifyNB(test_Matrix,self.p_0_Vec,self.p_1_Vec,self.pAbusive)\n",
    "            preds.append(pred)\n",
    "            \n",
    "        return preds\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# split word\n",
    "mySent = 'my dog has flea, problems help please.'\n",
    "mySent.split()\n",
    "#使用正则表达式去除标点\n",
    "regEx = re.compile('\\\\W*')\n",
    "listofTokens = regEx.split(mySent)\n",
    "#去除空格\n",
    "[tok for tok in listofTokens if len(tok)>0]\n",
    "#将大写字母全部改为小写\n",
    "[tok.lower() for tok in listofTokens if len(tok)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def words_split(dataset):\n",
    "    data_split = []\n",
    "    regEx = re.compile('\\\\W*')\n",
    "    for data in dataset:\n",
    "        data_temp = [d.lower() for d in regEx.split(data) if len(d)>0]\n",
    "        data_split.append(data_temp)\n",
    "    return data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['my dog has flea, problems help please',\n",
    "        'maybe not take him to dog park stupid',\n",
    "        'my dalmation is so cute I love him',\n",
    "        'stop posting stupid worthless garbage',\n",
    "         ' mr licks ate my steak how to stop him',\n",
    "        'quit buying worthless dog food stupid']\n",
    "words = words_split(words)\n",
    "classVec = [0,1,0,1,0,1]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes = bayes()\n",
    "myVocablist = bayes.createVocabList(words)\n",
    "#myword2Vec = bayes.setofWord2Vec(myVocablist,words[0])\n",
    "myword2Vec = []\n",
    "for word_1 in words :\n",
    "    myword2Vec.append(bayes.setofWord2Vec(myVocablist,word_1))\n",
    "len(myVocablist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = bayes()\n",
    "p_0_Vect, p_1_Vect, pAb = bayes.trainNB0(words,classVec)\n",
    "p_0_Vect, p_1_Vect, pAb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ['love my dalmation','stupid dog']\n",
    "test_data = words_split(test_data)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bayes.testingNB(test_data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
